# ==========================================
# ü©∫ TRUST-MED AI: H·ªÜ TH·ªêNG H·ªñ TR·ª¢ CH·∫®N ƒêO√ÅN UNG TH∆Ø V√ö
# ==========================================
# Phi√™n b·∫£n: Pro v4.0 (Giao di·ªán B√°c sƒ©)
# T√°c gi·∫£: [T√™n c·ªßa b·∫°n/Nh√≥m nghi√™n c·ª©u]

import streamlit as st
import torch
import numpy as np
import cv2
from PIL import Image
import segmentation_models_pytorch as smp
from torchvision import models, transforms
import os
import gdown
import matplotlib.pyplot as plt
import pandas as pd
import time

# =====================================================
# ‚öôÔ∏è C·∫§U H√åNH GIAO DI·ªÜN CHUNG
# =====================================================
st.set_page_config(
    page_title="TRUST-MED AI Support System",
    page_icon="ü©∫",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS cho giao di·ªán y t·∫ø chuy√™n nghi·ªáp
st.markdown("""
    <style>
    .main { background-color: #f8f9fa; }
    h1, h2, h3 { color: #2c3e50; font-family: 'Segoe UI', sans-serif; }
    .stAlert { border-radius: 8px; }
    .report-box {
        background-color: white;
        padding: 20px;
        border-radius: 10px;
        box-shadow: 0 4px 6px rgba(0,0,0,0.1);
        border-left: 5px solid #0066cc;
        margin-bottom: 20px;
    }
    .metric-card {
        text-align: center;
        padding: 10px;
        background: #f1f3f6;
        border-radius: 8px;
    }
    </style>
""", unsafe_allow_html=True)

# ============================
# 1. C·∫§U H√åNH & T·∫¢I MODEL
# ============================
DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'

# üî• FILE ID (MODEL C·ª¶A B·∫†N)
SEG_FILE_ID = '1eUtmSEXAh9r-o_qRSk5oaYK7yfxjITfl' 
CLS_FILE_ID = '1-v64E5VqSvbuKDYtdGDJBqUcWe9QfPVe'

SEG_PATH = 'TRUST_MED_SEG_MODEL.pth'
CLS_PATH = 'TRUST_MED_CLS_BIRADS_FINAL.pth'

@st.cache_resource
def load_models():
    # T·∫£i file n·∫øu ch∆∞a c√≥
    if not os.path.exists(SEG_PATH):
        with st.spinner("üì• ƒêang t·∫£i m√¥ h√¨nh Ph√¢n ƒëo·∫°n t·ª´ Cloud..."):
            gdown.download(f'https://drive.google.com/uc?id={SEG_FILE_ID}', SEG_PATH, quiet=True)
    if not os.path.exists(CLS_PATH):
        with st.spinner("üì• ƒêang t·∫£i m√¥ h√¨nh Ph√¢n lo·∫°i t·ª´ Cloud..."):
            gdown.download(f'https://drive.google.com/uc?id={CLS_FILE_ID}', CLS_PATH, quiet=True)

    # 1.1 LOAD SEGMENTATION (ResNet34 + U-Net + SCSE)
    # (L∆∞u √Ω: Code app c≈© c·ªßa b·∫°n d√πng ResNet34, t√¥i gi·ªØ nguy√™n ƒë·ªÉ kh·ªõp logic)
    seg_model = smp.Unet(encoder_name="resnet34", in_channels=3, classes=1, decoder_attention_type="scse")
    # Load safe: map location v·ªÅ CPU n·∫øu kh√¥ng c√≥ GPU
    seg_model.load_state_dict(torch.load(SEG_PATH, map_location=torch.device(DEVICE)))
    seg_model.to(DEVICE)
    seg_model.eval()
    
    # 1.2 LOAD CLASSIFICATION (EfficientNet-B4)
    cls_model = models.efficientnet_b4(weights=None)
    cls_model.classifier[1] = torch.nn.Linear(cls_model.classifier[1].in_features, 4)
    cls_model.load_state_dict(torch.load(CLS_PATH, map_location=torch.device(DEVICE)))
    cls_model.to(DEVICE)
    cls_model.eval()
    
    return seg_model, cls_model

# Load model ngay khi kh·ªüi ƒë·ªông
try:
    seg_model, cls_model = load_models()
except Exception as e:
    st.error(f"‚ùå L·ªói kh·ªüi ƒë·ªông h·ªá th·ªëng AI: {e}")
    st.stop()

# ============================
# 2. C√ÅC H√ÄM X·ª¨ L√ù ·∫¢NH (LOGIC C≈®)
# ============================
def validate_image(image_pil):
    img_np = np.array(image_pil)
    if img_np.shape[0] < 100 or img_np.shape[1] < 100: return False, "K√≠ch th∆∞·ªõc qu√° nh·ªè"
    if len(img_np.shape) == 3:
        if np.std(img_np, axis=2).mean() > 20: return False, "·∫¢nh m√†u (kh√¥ng ph·∫£i si√™u √¢m)"
    gray = cv2.cvtColor(img_np, cv2.COLOR_RGB2GRAY)
    if cv2.Laplacian(gray, cv2.CV_64F).var() < 5: return False, "·∫¢nh qu√° m·ªù/ƒëen"
    return True, "H·ª£p l·ªá"

def letterbox_image(image, size):
    iw, ih = image.size; w, h = size
    scale = min(w/iw, h/ih)
    nw = int(iw*scale); nh = int(ih*scale)
    image = image.resize((nw,nh), Image.BICUBIC)
    new_image = Image.new('RGB', size, (0,0,0))
    new_image.paste(image, ((w-nw)//2, (h-nh)//2))
    return new_image, nw, nh, (w-nw)//2, (h-nh)//2

def post_process_mask(mask_prob, threshold=0.5):
    mask_binary = (mask_prob > threshold).astype(np.uint8)
    kernel = np.ones((5,5), np.uint8)
    mask_binary = cv2.morphologyEx(mask_binary, cv2.MORPH_OPEN, kernel)
    mask_binary = cv2.morphologyEx(mask_binary, cv2.MORPH_CLOSE, kernel)
    num, labels, stats, _ = cv2.connectedComponentsWithStats(mask_binary, connectivity=8)
    if num > 1:
        max_label = 1 + np.argmax(stats[1:, cv2.CC_STAT_AREA])
        mask_clean = np.zeros_like(mask_binary)
        mask_clean[labels == max_label] = 1
        return mask_clean
    return mask_binary

def get_bounding_box(mask_pred, padding=0.2):
    cnts, _ = cv2.findContours(mask_pred, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    if cnts:
        c = max(cnts, key=cv2.contourArea)
        x, y, w, h = cv2.boundingRect(c)
        pad_w = int(w*padding); pad_h = int(h*padding)
        x1 = max(0, x-pad_w); y1 = max(0, y-pad_h)
        x2 = min(mask_pred.shape[1], x+w+pad_w)
        y2 = min(mask_pred.shape[0], y+h+pad_h)
        return (x1, y1, x2, y2), "ROI"
    return (0,0,0,0), "None"

class GradCAM:
    def __init__(self, model, target_layer):
        self.model = model; self.target_layer = target_layer
        self.gradients = None; self.activations = None
        target_layer.register_forward_hook(self.save_activation)
        target_layer.register_full_backward_hook(self.save_gradient)
    def save_activation(self, module, input, output): self.activations = output
    def save_gradient(self, module, grad_input, grad_output): self.gradients = grad_output[0]
    def __call__(self, x):
        output = self.model(x); idx = torch.argmax(output)
        self.model.zero_grad(); output[0, idx].backward()
        grads = self.gradients[0]; acts = self.activations[0]
        weights = torch.mean(grads, dim=(1, 2), keepdim=True)
        cam = torch.sum(weights * acts, dim=0).cpu().detach().numpy()
        cam = np.maximum(cam, 0)
        cam = cv2.resize(cam, (224, 224))
        cam = (cam - np.min(cam)) / (np.max(cam) + 1e-8)
        return cam, int(idx), torch.nn.functional.softmax(output, dim=1)

cam_extractor = GradCAM(cls_model, cls_model.features[-1])

def calc_trust_score(probs, mask_area_ratio):
    probs_np = probs.detach().cpu().numpy()[0]
    entropy = -np.sum(probs_np * np.log(probs_np + 1e-9))
    score_cls = 1.0 - (entropy / np.log(4))
    score_seg = 0.3 if mask_area_ratio < 0.01 else 0.95
    return 0.7 * score_cls + 0.3 * score_seg

# =====================================================
# 4) SIDEBAR & CH·ªåN TRANG (NAVIGATION)
# =====================================================
st.sidebar.image("https://cdn-icons-png.flaticon.com/512/3004/3004458.png", width=80)
st.sidebar.title("TRUST-MED AI")
st.sidebar.markdown("**H·ªá th·ªëng h·ªó tr·ª£ ch·∫©n ƒëo√°n h√¨nh ·∫£nh**")
st.sidebar.markdown("---")

menu = st.sidebar.radio(
    "Danh m·ª•c ch·ª©c nƒÉng:",
    ["üè† B√†n l√†m vi·ªác (Ch·∫©n ƒëo√°n)", "üìñ H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng", "üìö C∆° s·ªü d·ªØ li·ªáu hu·∫•n luy·ªán", "‚ÑπÔ∏è Gi·ªõi thi·ªáu d·ª± √°n"]
)

# =====================================================
# TRANG 1: B√ÄN L√ÄM VI·ªÜC (MAIN APP)
# =====================================================
if menu == "üè† B√†n l√†m vi·ªác (Ch·∫©n ƒëo√°n)":
    st.title("üñ•Ô∏è B√†n l√†m vi·ªác B√°c sƒ©")
    st.info("üí° **G·ª£i √Ω:** T·∫£i ·∫£nh si√™u √¢m l√™n ƒë·ªÉ AI ph√¢n t√≠ch t·ª± ƒë·ªông. K·∫øt qu·∫£ ch·ªâ mang t√≠nh tham kh·∫£o.")

    col_left, col_right = st.columns([1, 2])

    with col_left:
        st.subheader("üì• Nh·∫≠p d·ªØ li·ªáu")
        uploaded_file = st.file_uploader("Ch·ªçn ·∫£nh si√™u √¢m (JPG/PNG/DICOM)", type=["jpg", "png", "jpeg"])
        
        with st.expander("‚öôÔ∏è C·∫•u h√¨nh n√¢ng cao"):
            seg_threshold = st.slider("ƒê·ªô nh·∫°y t√¨m kh·ªëi u", 0.1, 0.9, 0.5, 0.05)
            use_post_process = st.checkbox("B·∫≠t kh·ª≠ nhi·ªÖu t·ª± ƒë·ªông", value=True)

    with col_right:
        if uploaded_file is None:
            st.warning("üëà Vui l√≤ng t·∫£i ·∫£nh l√™n ƒë·ªÉ b·∫Øt ƒë·∫ßu.")
            st.image("https://img.freepik.com/free-vector/doctor-examining-patient-clinic_23-2148856559.jpg", width=400, caption="H·ªá th·ªëng s·∫µn s√†ng...")
        else:
            # X·ª¨ L√ù & HI·ªÇN TH·ªä
            original_pil = Image.open(uploaded_file).convert("RGB")
            original_np = np.array(original_pil)
            
            # Guardrail
            is_valid, msg = validate_image(original_pil)
            if not is_valid:
                st.error(f"‚õîÔ∏è ·∫¢NH KH√îNG H·ª¢P L·ªÜ: {msg}")
            else:
                progress_bar = st.progress(0, text="ƒêang kh·ªüi t·∫°o...")
                
                # --- B∆Ø·ªöC 1: PH√ÇN ƒêO·∫†N ---
                progress_bar.progress(30, text="ƒêang ph√¢n ƒëo·∫°n t·ªïn th∆∞∆°ng (U-Net)...")
                input_pil, nw, nh, dx, dy = letterbox_image(original_pil, (256, 256))
                to_tensor = transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])
                input_tensor = to_tensor(input_pil).unsqueeze(0).to(DEVICE)
                
                with torch.no_grad():
                    mask_prob = torch.sigmoid(seg_model(input_tensor)).cpu().numpy()[0,0]
                
                mask_valid = mask_prob[dy:dy+nh, dx:dx+nw]
                mask_resized = cv2.resize(mask_valid, (original_np.shape[1], original_np.shape[0]))
                
                if use_post_process: mask_binary = post_process_mask(mask_resized, threshold=seg_threshold)
                else: mask_binary = (mask_resized > seg_threshold).astype(np.uint8)
                
                # --- B∆Ø·ªöC 2: C·∫ÆT ROI & PH√ÇN LO·∫†I ---
                progress_bar.progress(60, text="ƒêang ph√¢n t√≠ch b·ªánh h·ªçc (EfficientNet)...")
                (x1, y1, x2, y2), roi_status = get_bounding_box(mask_binary)
                roi_img = original_np[y1:y2, x1:x2]
                
                # Visuals
                mask_display = original_np.copy()
                mask_display[mask_binary == 1] = [0, 255, 0]
                overlay = cv2.addWeighted(original_np, 0.7, mask_display, 0.3, 0)
                cv2.rectangle(overlay, (x1, y1), (x2, y2), (255, 0, 0), 2)
                
                # Classification Logic
                roi_pil = Image.fromarray(roi_img)
                trans_cls = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])
                input_cls = trans_cls(roi_pil).unsqueeze(0).to(DEVICE)
                
                heatmap, pred_idx, probs = cam_extractor(input_cls)
                mask_ratio = np.sum(mask_binary) / (original_np.shape[0]*original_np.shape[1])
                trust_score = calc_trust_score(probs, mask_ratio)
                
                probs_np = probs.detach().cpu().numpy()[0]
                prob_benign = probs_np[0] + probs_np[1]
                prob_malignant = probs_np[2] + probs_np[3]
                
                # Logic K·∫øt lu·∫≠n
                if mask_ratio < 0.005:
                    status = "KH√îNG PH√ÅT HI·ªÜN B·∫§T TH∆Ø·ªúNG (BI-RADS 1)"; color = "green"
                    prob_display = 0.05 # Gi·∫£ l·∫≠p th·∫•p
                else:
                    if prob_malignant > prob_benign:
                        status = "NGHI NG·ªú √ÅC T√çNH (BI-RADS 4/5)"; color = "red"
                        prob_display = prob_malignant
                    else:
                        status = "KH·∫¢ NƒÇNG CAO L√ÄNH T√çNH (BI-RADS 2/3)"; color = "blue"
                        prob_display = prob_benign
                
                progress_bar.progress(100, text="Ho√†n t·∫•t!")
                time.sleep(0.5); progress_bar.empty()
                
                # --- B∆Ø·ªöC 3: HI·ªÇN TH·ªä K·∫æT QU·∫¢ (DASHBOARD STYLE) ---
                st.markdown(f"""
                <div class="report-box">
                    <h3 style="color:{color}; margin-top:0;">üìã K·∫æT QU·∫¢: {status}</h3>
                    <p><b>ƒê·ªô tin c·∫≠y c·ªßa AI:</b> {trust_score:.1%}</p>
                </div>
                """, unsafe_allow_html=True)
                
                # Metrics
                m1, m2, m3 = st.columns(3)
                m1.metric("X√°c su·∫•t L√†nh t√≠nh", f"{prob_benign:.1%}")
                m2.metric("X√°c su·∫•t √Åc t√≠nh", f"{prob_malignant:.1%}", delta_color="inverse")
                m3.metric("Di·ªán t√≠ch t·ªïn th∆∞∆°ng", f"{mask_ratio*100:.2f}% ·∫£nh")
                
                st.divider()
                st.subheader("üî¨ H√¨nh ·∫£nh ph√¢n t√≠ch chi ti·∫øt")
                
                tab_img1, tab_img2, tab_img3 = st.tabs(["1. ·∫¢nh G·ªëc", "2. ƒê·ªãnh v·ªã T·ªïn th∆∞∆°ng", "3. B·∫£n ƒë·ªì nhi·ªát AI"])
                
                with tab_img1:
                    st.image(original_pil, use_column_width=True)
                with tab_img2:
                    st.image(overlay, caption="V√πng xanh l√°: Kh·ªëi u | Khung xanh d∆∞∆°ng: ROI", use_column_width=True)
                with tab_img3:
                    hm_color = cv2.applyColorMap(np.uint8(255*heatmap), cv2.COLORMAP_JET)
                    hm_color = cv2.cvtColor(hm_color, cv2.COLOR_BGR2RGB)
                    superimposed = cv2.addWeighted(cv2.resize(roi_img, (224,224)), 0.6, hm_color, 0.4, 0)
                    st.image(superimposed, caption="V√πng m√†u ƒë·ªè l√† n∆°i AI t·∫≠p trung ƒë·ªÉ ch·∫©n ƒëo√°n", use_column_width=True)

# =====================================================
# TRANG 2: H∆Ø·ªöNG D·∫™N S·ª¨ D·ª§NG
# =====================================================
elif menu == "üìñ H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng":
    st.title("üìñ H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng TRUST-MED")
    st.markdown("""
    ### Ch√†o m·ª´ng b√°c sƒ© ƒë·∫øn v·ªõi h·ªá th·ªëng!
    D∆∞·ªõi ƒë√¢y l√† quy tr√¨nh 3 b∆∞·ªõc ƒë·ªÉ s·ª≠ d·ª•ng ph·∫ßn m·ªÅm hi·ªáu qu·∫£:

    #### B∆∞·ªõc 1: Chu·∫©n b·ªã h√¨nh ·∫£nh
    * H·ªá th·ªëng h·ªó tr·ª£ c√°c ƒë·ªãnh d·∫°ng ·∫£nh ph·ªï bi·∫øn: **JPG, PNG, JPEG**.
    * ·∫¢nh n√™n l√† ·∫£nh si√™u √¢m th√¥ (B-mode), h·∫°n ch·∫ø c√°c ·∫£nh c√≥ ch·ª©a m≈©i t√™n ch·ªâ d·∫´n ho·∫∑c marker m√†u c·ªßa m√°y si√™u √¢m c≈© ƒë·ªÉ tr√°nh nhi·ªÖu.

    #### B∆∞·ªõc 2: T·∫£i ·∫£nh v√† Ph√¢n t√≠ch
    1. Truy c·∫≠p v√†o m·ª•c **"üè† B√†n l√†m vi·ªác"** ·ªü menu b√™n tr√°i.
    2. Nh·∫•n n√∫t **"Browse files"** ƒë·ªÉ ch·ªçn ·∫£nh t·ª´ m√°y t√≠nh.
    3. H·ªá th·ªëng s·∫Ω t·ª± ƒë·ªông ch·∫°y qua 2 m√¥ h√¨nh AI:
        * **Segmentation Model:** ƒê·ªÉ t√¨m v√† khoanh v√πng kh·ªëi u.
        * **Classification Model:** ƒê·ªÉ ƒë√°nh gi√° t√≠nh ch·∫•t l√†nh/√°c.

    #### B∆∞·ªõc 3: ƒê·ªçc k·∫øt qu·∫£
    * **Thanh tr·∫°ng th√°i:** S·∫Ω hi·ªán m√†u ƒê·ªé (Nguy hi·ªÉm), XANH D∆Ø∆†NG (L√†nh t√≠nh) ho·∫∑c XANH L√Å (B√¨nh th∆∞·ªùng).
    * **H√¨nh ·∫£nh tr·ª±c quan:** B√°c sƒ© c√≥ th·ªÉ xem tab "B·∫£n ƒë·ªì nhi·ªát" ƒë·ªÉ bi·∫øt AI ƒëang nghi ng·ªù v√πng n√†o nh·∫•t tr√™n kh·ªëi u (v√πng m√†u ƒë·ªè r·ª±c).
    """)

# =====================================================
# TRANG 3: C∆† S·ªû D·ªÆ LI·ªÜU
# =====================================================
elif menu == "üìö C∆° s·ªü d·ªØ li·ªáu hu·∫•n luy·ªán":
    st.title("üìä Ngu·ªìn d·ªØ li·ªáu hu·∫•n luy·ªán")
    st.markdown("H·ªá th·ªëng TRUST-MED ƒë∆∞·ª£c hu·∫•n luy·ªán tr√™n **12 b·ªô d·ªØ li·ªáu** uy t√≠n (c√¥ng khai v√† n·ªôi b·ªô), ƒë·∫£m b·∫£o t√≠nh ƒëa d·∫°ng sinh h·ªçc v√† kh·∫£ nƒÉng kh√°ng nhi·ªÖu.")
    
    # Danh s√°ch 12 dataset chu·∫©n
    datasets = [
        ("BUSI (Breast Ultrasound Images)", "Cairo Univ", "Dataset chu·∫©n v√†ng v·ªõi nh√£n ph√¢n ƒëo·∫°n chi ti·∫øt."),
        ("BUSBRA (Brazil)", "ƒêa trung t√¢m", "D·ªØ li·ªáu thu th·∫≠p t·ª´ nhi·ªÅu d√≤ng m√°y si√™u √¢m kh√°c nhau."),
        ("UDIAT (T√¢y Ban Nha)", "B·ªánh vi·ªán Parc Taul√≠", "Chuy√™n v·ªÅ c√°c t·ªïn th∆∞∆°ng nh·ªè (small lesions)."),
        ("OASBUD (Ba Lan)", "D·ªØ li·ªáu m·ªü", "K√®m theo nh√£n BI-RADS chu·∫©n."),
        ("STU (Trung Qu·ªëc)", "Shantou Univ", "Dataset l·ªõn khu v·ª±c Ch√¢u √Å."),
        ("Thamburaj Dataset", "T∆∞ nh√¢n", "T·∫≠p trung v√†o ƒë·∫∑c tr∆∞ng h√¨nh th√°i h·ªçc."),
        ("HMSS (Mexico)", "Hospital Move", "D·ªØ li·ªáu l√¢m s√†ng th·ª±c t·∫ø."),
        ("Mendeley Data V2", "Rodrigues et al.", "C√¢n b·∫±ng gi·ªØa L√†nh v√† √Åc."),
        ("BrEaST-Lesions", "Kaggle", "T·ªïng h·ª£p ƒëa ngu·ªìn."),
        ("Dataset A (Private)", "N·ªôi b·ªô", "D·ªØ li·ªáu b·ªï sung ƒë·ªÉ c√¢n b·∫±ng l·ªõp."),
        ("VinDr-Mammo (Tham chi·∫øu)", "VinBigData", "D·ªØ li·ªáu ƒë·∫∑c th√π ng∆∞·ªùi Vi·ªát Nam."),
        ("HisBreast (Vi·ªát Nam)", "B·ªánh vi·ªán VN", "D·ªØ li·ªáu l√¢m s√†ng tr·ªçng ƒëi·ªÉm c·ªßa ƒë·ªÅ t√†i.")
    ]
    
    for i, (name, source, desc) in enumerate(datasets):
        with st.expander(f"{i+1}. {name}"):
            st.markdown(f"**Ngu·ªìn:** {source}")
            st.markdown(f"**M√¥ t·∫£:** {desc}")

# =====================================================
# TRANG 4: GI·ªöI THI·ªÜU
# =====================================================
elif menu == "‚ÑπÔ∏è Gi·ªõi thi·ªáu d·ª± √°n":
    st.title("‚ÑπÔ∏è V·ªÅ d·ª± √°n TRUST-MED")
    st.markdown("""
    ### üéØ M·ª•c ti√™u
    X√¢y d·ª±ng h·ªá th·ªëng AI h·ªó tr·ª£ ch·∫©n ƒëo√°n ung th∆∞ v√∫ t·ª± ƒë·ªông, gi√∫p gi·∫£m t·∫£i cho b√°c sƒ© ch·∫©n ƒëo√°n h√¨nh ·∫£nh v√† tƒÉng ƒë·ªô ch√≠nh x√°c trong t·∫ßm so√°t s·ªõm.

    ### üõ†Ô∏è C√¥ng ngh·ªá l√µi
    * **Ph√¢n ƒëo·∫°n (Segmentation):** U-Net v·ªõi ki·∫øn tr√∫c ResNet34 v√† c∆° ch·∫ø Attention (scSE) gi√∫p b·∫Øt tr·ªçn bi√™n d·∫°ng kh·ªëi u.
    * **Ph√¢n lo·∫°i (Classification):** EfficientNet-B4 - m·ªôt trong nh·ªØng m√¥ h√¨nh CNN hi·ªáu qu·∫£ nh·∫•t hi·ªán nay.
    * **Gi·∫£i th√≠ch (XAI):** T√≠ch h·ª£p Grad-CAM ƒë·ªÉ minh b·∫°ch h√≥a quy·∫øt ƒë·ªãnh c·ªßa AI.

    ### ‚ö†Ô∏è Tuy√™n b·ªë mi·ªÖn tr·ª´ tr√°ch nhi·ªám
    * ·ª®ng d·ª•ng n√†y l√† s·∫£n ph·∫©m nghi√™n c·ª©u khoa h·ªçc.
    * K·∫øt qu·∫£ c·ªßa AI **kh√¥ng thay th·∫ø** ch·∫©n ƒëo√°n c·ªßa b√°c sƒ© chuy√™n khoa.
    * Ng∆∞·ªùi d√πng ch·ªãu tr√°ch nhi·ªám khi s·ª≠ d·ª•ng th√¥ng tin t·ª´ ·ª©ng d·ª•ng n√†y.
    """)
