import streamlit as st
import torch
import numpy as np
import cv2
from PIL import Image
import segmentation_models_pytorch as smp
from torchvision import models, transforms
import os
import gdown
import matplotlib.pyplot as plt

# --- C·∫§U H√åNH ---
st.set_page_config(page_title="TRUST-MED AI", page_icon="ü©∫", layout="wide")
DEVICE = 'cpu' # Ch·∫°y tr√™n Streamlit Cloud d√πng CPU

# üî• FILE ID (ƒê√£ c·∫≠p nh·∫≠t t·ª´ link b·∫°n g·ª≠i)
SEG_FILE_ID = '1eUtmSEXAh9r-o_qRSk5oaYK7yfxjITfl' 
CLS_FILE_ID = '1-v64E5VqSvbuKDYtdGDJBqUcWe9QfPVe'

SEG_PATH = 'TRUST_MED_SEG_MODEL.pth'
CLS_PATH = 'TRUST_MED_CLS_BIRADS_FINAL.pth'

# --- 1. T·∫¢I V√Ä LOAD MODEL ---
@st.cache_resource
def load_models():
    # T·∫£i file t·ª´ Drive n·∫øu ch∆∞a c√≥ (Ch·∫°y 1 l·∫ßn duy nh·∫•t)
    if not os.path.exists(SEG_PATH):
        url = f'https://drive.google.com/uc?id={SEG_FILE_ID}'
        gdown.download(url, SEG_PATH, quiet=False)
    
    if not os.path.exists(CLS_PATH):
        url = f'https://drive.google.com/uc?id={CLS_FILE_ID}'
        gdown.download(url, CLS_PATH, quiet=False)

    # Load Segmentation Model
    seg_model = smp.Unet(encoder_name="resnet34", in_channels=3, classes=1, decoder_attention_type="scse")
    seg_model.load_state_dict(torch.load(SEG_PATH, map_location=torch.device(DEVICE)))
    seg_model.eval()
    
    # Load Classification Model
    cls_model = models.efficientnet_b4(weights=None)
    cls_model.classifier[1] = torch.nn.Linear(cls_model.classifier[1].in_features, 4)
    cls_model.load_state_dict(torch.load(CLS_PATH, map_location=torch.device(DEVICE)))
    cls_model.eval()
    
    return seg_model, cls_model

try:
    with st.spinner("‚è≥ ƒêang t·∫£i d·ªØ li·ªáu t·ª´ ƒë√°m m√¢y (L·∫ßn ƒë·∫ßu m·∫•t kho·∫£ng 1 ph√∫t)..."):
        seg_model, cls_model = load_models()
except Exception as e:
    st.error(f"L·ªói kh·ªüi ƒë·ªông: {e}. Vui l√≤ng ki·ªÉm tra l·∫°i k·∫øt n·ªëi m·∫°ng.")
    st.stop()

# --- 2. C√ÅC H√ÄM X·ª¨ L√ù ·∫¢NH ---
def get_bounding_box(mask_pred, padding=0.2):
    """T√¨m t·ªça ƒë·ªô kh·ªëi u ƒë·ªÉ v·∫Ω v√† c·∫Øt"""
    contours, _ = cv2.findContours(mask_pred, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    if contours:
        c = max(contours, key=cv2.contourArea)
        x, y, rw, rh = cv2.boundingRect(c)
        # M·ªü r·ªông v√πng (Padding)
        pad_w = int(rw * padding); pad_h = int(rh * padding)
        x1 = max(0, x - pad_w); y1 = max(0, y - pad_h)
        x2 = min(mask_pred.shape[1], x + rw + pad_w)
        y2 = min(mask_pred.shape[0], y + rh + pad_h)
        return (x1, y1, x2, y2), "Soft-ROI"
    else:
        # Fallback trung t√¢m
        h, w = mask_pred.shape
        cy, cx = h//2, w//2; sz = min(h, w)//2
        return (cx-sz, cy-sz, cx+sz, cy+sz), "Fallback"

class GradCAM:
    def __init__(self, model, target_layer):
        self.model = model; self.target_layer = target_layer
        self.gradients = None; self.activations = None
        target_layer.register_forward_hook(self.save_activation)
        target_layer.register_full_backward_hook(self.save_gradient)
    def save_activation(self, module, input, output): self.activations = output
    def save_gradient(self, module, grad_input, grad_output): self.gradients = grad_output[0]
    def __call__(self, x):
        output = self.model(x); idx = torch.argmax(output)
        self.model.zero_grad(); output[0, idx].backward()
        grads = self.gradients[0]; acts = self.activations[0]
        weights = torch.mean(grads, dim=(1, 2), keepdim=True)
        cam = torch.sum(weights * acts, dim=0).cpu().detach().numpy()
        cam = np.maximum(cam, 0)
        cam = cv2.resize(cam, (224, 224))
        cam = (cam - np.min(cam)) / (np.max(cam) + 1e-8)
        return cam, int(idx), torch.nn.functional.softmax(output, dim=1)

cam_extractor = GradCAM(cls_model, cls_model.features[-1])

def calc_trust_score(probs, mask_area_ratio):
    probs_np = probs.detach().numpy()[0]
    entropy = -np.sum(probs_np * np.log(probs_np + 1e-9))
    max_ent = np.log(4)
    score_cls = 1.0 - (entropy / max_ent)
    score_seg = 0.3 if mask_area_ratio < 0.01 else 0.95
    return 0.7 * score_cls + 0.3 * score_seg

# --- 3. GIAO DI·ªÜN CH√çNH ---
st.title("ü©∫ TRUST-MED: H·ªá th·ªëng Ch·∫©n ƒëo√°n Ung th∆∞ V√∫ ƒêa trung t√¢m")
st.markdown("---")

col_upload, col_info = st.columns([1, 2])
with col_upload:
    uploaded_file = st.file_uploader("T·∫£i ·∫£nh si√™u √¢m:", type=["jpg", "png", "jpeg"])

if uploaded_file is not None:
    # --- X·ª¨ L√ù ·∫¢NH ---
    image = Image.open(uploaded_file).convert("RGB")
    img_np = np.array(image)
    
    with st.spinner("ü§ñ AI ƒëang ph√¢n t√≠ch to√†n di·ªán..."):
        # 1. Ph√¢n ƒëo·∫°n (Segmentation)
        preprocess_seg = transforms.Compose([
            transforms.Resize((256, 256)), transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ])
        input_seg = preprocess_seg(image).unsqueeze(0).to(DEVICE)
        with torch.no_grad():
            mask_logits = seg_model(input_seg)
            mask_pred = (torch.sigmoid(mask_logits) > 0.5).float().numpy()[0,0]
        
        # Resize mask v·ªÅ g·ªëc & T√≠nh t·ª∑ l·ªá di·ªán t√≠ch
        mask_resized = cv2.resize(mask_pred, (img_np.shape[1], img_np.shape[0]), interpolation=cv2.INTER_NEAREST)
        mask_ratio = np.sum(mask_resized) / (img_np.shape[0]*img_np.shape[1])
        
        # 2. L·∫•y t·ªça ƒë·ªô Box & C·∫Øt ROI
        (x1, y1, x2, y2), roi_type = get_bounding_box(mask_resized.astype(np.uint8))
        roi_img = img_np[y1:y2, x1:x2]
        
        # 3. V·∫Ω Bounding Box l√™n ·∫£nh g·ªëc (Khoanh v√πng)
        img_with_box = img_np.copy()
        cv2.rectangle(img_with_box, (x1, y1), (x2, y2), (0, 255, 0), 2) # M√†u xanh l√°
        cv2.putText(img_with_box, "AI Detected", (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

        # 4. Ph√¢n lo·∫°i & Grad-CAM
        roi_pil = Image.fromarray(roi_img)
        trans_cls = transforms.Compose([
            transforms.Resize((224, 224)), transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ])
        input_cls = trans_cls(roi_pil).unsqueeze(0).to(DEVICE)
        
        heatmap, pred_idx, probs = cam_extractor(input_cls)
        trust_score = calc_trust_score(probs, mask_ratio)
        
        # 5. T√≠nh nh√≥m x√°c su·∫•t L√†nh/√Åc
        probs_np = probs.detach().numpy()[0]
        prob_benign = probs_np[0] + probs_np[1] # BR2 + BR3
        prob_malignant = probs_np[2] + probs_np[3] # BR4A + BR4B+
        
        # X·ª≠ l√Ω tr∆∞·ªùng h·ª£p "B√¨nh th∆∞·ªùng" (Kh√¥ng c√≥ u)
        prob_normal = 0.0
        if mask_ratio < 0.005: # N·∫øu di·ªán t√≠ch u < 0.5% ·∫£nh
            prob_normal = 0.95
            prob_benign = 0.05
            prob_malignant = 0.0
            status_text = "B√¨nh th∆∞·ªùng (Kh√¥ng ph√°t hi·ªán u)"
            status_color = "green"
        else:
            if prob_malignant > prob_benign:
                status_text = "Nghi ng·ªù √ÅC T√çNH"
                status_color = "red"
            else:
                status_text = "Kh·∫£ nƒÉng cao L√ÄNH T√çNH"
                status_color = "blue"

    # --- HI·ªÇN TH·ªä K·∫æT QU·∫¢ ---
    # H√†ng 1: H√¨nh ·∫£nh tr·ª±c quan
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.image(img_with_box, caption="Khoanh v√πng t·ªïn th∆∞∆°ng (Detection)", use_column_width=True)
    
    with col2:
        # Overlay Grad-CAM
        heatmap_colored = cv2.applyColorMap(np.uint8(255*heatmap), cv2.COLORMAP_JET)
        heatmap_colored = cv2.cvtColor(heatmap_colored, cv2.COLOR_BGR2RGB)
        superimposed = cv2.addWeighted(cv2.resize(roi_img, (224,224)), 0.6, heatmap_colored, 0.4, 0)
        st.image(superimposed, caption="V√πng AI 'soi' (Grad-CAM)", use_column_width=True)
        
    with col3:
        st.subheader("üìä K·∫øt qu·∫£ ph√¢n t√≠ch")
        st.markdown(f"Ch·∫©n ƒëo√°n: **:{status_color}[{status_text}]**")
        if prob_normal < 0.5:
            st.markdown(f"Chi ti·∫øt: **BI-RADS {['2', '3', '4A', '4B+'][pred_idx]}**")
        st.markdown(f"ƒê·ªô tin c·∫≠y: **{trust_score:.1%}**")
        
        st.markdown("---")
        st.write("X√°c su·∫•t b·ªánh h·ªçc:")
        if prob_normal > 0.5:
             st.progress(int(prob_normal * 100), text=f"M√¥ b√¨nh th∆∞·ªùng: {prob_normal:.1%}")
        else:
            st.progress(int(prob_benign * 100), text=f"L√†nh t√≠nh / Theo d√µi: {prob_benign:.1%}")
            st.progress(int(prob_malignant * 100), text=f"√Åc t√≠nh (Nguy c∆° cao): {prob_malignant:.1%}")
        

    # C·∫£nh b√°o cu·ªëi
    if trust_score < 0.4 and prob_normal < 0.5:
        st.warning("‚ö†Ô∏è C·∫¢NH B√ÅO: ƒê·ªô tin c·∫≠y th·∫•p. Vui l√≤ng ki·ªÉm tra l·∫°i g√≥c ch·ª•p ho·∫∑c tham v·∫•n b√°c sƒ©.")
    elif pred_idx == 3 and prob_normal < 0.5:
        st.error("üö® KHUY·∫æN NGH·ªä: C·∫ßn th·ª±c hi·ªán sinh thi·∫øt ngay ƒë·ªÉ x√°c ƒë·ªãnh kh·ªëi u.")
    elif prob_normal > 0.5:
        st.success("‚úÖ Kh√¥ng ph√°t hi·ªán d·∫•u hi·ªáu b·∫•t th∆∞·ªùng.")

    with st.expander("üîç Xem th√¥ng s·ªë k·ªπ thu·∫≠t (Debug Info)"):
        st.json({
            "Probabilities": {
                "BI-RADS 2": f"{probs_np[0]:.4f}",
                "BI-RADS 3": f"{probs_np[1]:.4f}",
                "BI-RADS 4A": f"{probs_np[2]:.4f}",
                "BI-RADS 4B+": f"{probs_np[3]:.4f}"
            },
            "Segmentation Info": {
                "Tumor Area Ratio": f"{mask_ratio:.4f}",
                "ROI Mode": roi_type
            }
        })
