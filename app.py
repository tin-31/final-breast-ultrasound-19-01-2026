import streamlit as st
import torch
import numpy as np
import cv2
from PIL import Image
import segmentation_models_pytorch as smp
from torchvision import models, transforms
import os
import gdown
import matplotlib.pyplot as plt
import time

# --- C·∫§U H√åNH GIAO DI·ªÜN ---
st.set_page_config(
    page_title="TRUST-MED: AI H·ªó tr·ª£ Ch·∫©n ƒëo√°n Ung th∆∞ V√∫",
    page_icon="ü©∫",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS T√πy ch·ªânh ƒë·ªÉ giao di·ªán ƒë·∫πp v√† chuy√™n nghi·ªáp h∆°n
st.markdown("""
    <style>
    .main {
        background-color: #f8f9fa;
    }
    .stTabs [data-baseweb="tab-list"] {
        gap: 24px;
    }
    .stTabs [data-baseweb="tab"] {
        height: 50px;
        white-space: pre-wrap;
        background-color: #ffffff;
        border-radius: 4px 4px 0px 0px;
        gap: 1px;
        padding-top: 10px;
        padding-bottom: 10px;
    }
    .stTabs [aria-selected="true"] {
        background-color: #e6f3ff;
        color: #0066cc;
        font-weight: bold;
    }
    .report-card {
        padding: 20px;
        border-radius: 10px;
        background-color: white;
        box-shadow: 0 4px 6px rgba(0,0,0,0.1);
        margin-bottom: 20px;
    }
    h1, h2, h3 {
        color: #2c3e50;
    }
    </style>
""", unsafe_allow_html=True)

# --- C·∫§U H√åNH MODEL ---
DEVICE = 'cpu' # Ho·∫∑c 'cuda' n·∫øu deploy tr√™n GPU

# üî• FILE ID
SEG_FILE_ID = '1eUtmSEXAh9r-o_qRSk5oaYK7yfxjITfl' 
CLS_FILE_ID = '1-v64E5VqSvbuKDYtdGDJBqUcWe9QfPVe'

SEG_PATH = 'TRUST_MED_SEG_MODEL.pth'
CLS_PATH = 'TRUST_MED_CLS_BIRADS_FINAL.pth'

# --- 1. T·∫¢I & LOAD MODEL (GI·ªÆ NGUY√äN LOGIC C≈®) ---
@st.cache_resource
def load_models():
    if not os.path.exists(SEG_PATH):
        gdown.download(f'https://drive.google.com/uc?id={SEG_FILE_ID}', SEG_PATH, quiet=False)
    if not os.path.exists(CLS_PATH):
        gdown.download(f'https://drive.google.com/uc?id={CLS_FILE_ID}', CLS_PATH, quiet=False)

    # Model Segment: ResNet34 + U-Net + SCSE
    seg_model = smp.Unet(encoder_name="resnet34", in_channels=3, classes=1, decoder_attention_type="scse")
    seg_model.load_state_dict(torch.load(SEG_PATH, map_location=torch.device(DEVICE)))
    seg_model.eval()
    
    # Model Classify: EfficientNet-B4
    cls_model = models.efficientnet_b4(weights=None)
    cls_model.classifier[1] = torch.nn.Linear(cls_model.classifier[1].in_features, 4)
    cls_model.load_state_dict(torch.load(CLS_PATH, map_location=torch.device(DEVICE)))
    cls_model.eval()
    
    return seg_model, cls_model

# --- 2. C√ÅC H√ÄM X·ª¨ L√ù ·∫¢NH (GI·ªÆ NGUY√äN) ---
def validate_image(image_pil):
    img_np = np.array(image_pil)
    if img_np.shape[0] < 100 or img_np.shape[1] < 100:
        return False, "K√≠ch th∆∞·ªõc ·∫£nh qu√° nh·ªè."
    if len(img_np.shape) == 3:
        std_color = np.std(img_np, axis=2).mean()
        if std_color > 15: 
            return False, "Ph√°t hi·ªán ·∫£nh m√†u. Vui l√≤ng ch·ªâ t·∫£i l√™n ·∫£nh si√™u √¢m (ƒëen tr·∫Øng)."
    gray = cv2.cvtColor(img_np, cv2.COLOR_RGB2GRAY)
    laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()
    if laplacian_var < 5:
        return False, "·∫¢nh qu√° m·ªù ho·∫∑c ƒëen tr∆°n (Kh√¥ng c√≥ t√≠n hi·ªáu)."
    return True, "H·ª£p l·ªá"

def letterbox_image(image, size):
    iw, ih = image.size
    w, h = size
    scale = min(w/iw, h/ih)
    nw = int(iw*scale)
    nh = int(ih*scale)
    image = image.resize((nw,nh), Image.BICUBIC)
    new_image = Image.new('RGB', size, (0,0,0))
    new_image.paste(image, ((w-nw)//2, (h-nh)//2))
    return new_image, nw, nh, (w-nw)//2, (h-nh)//2

def post_process_mask(mask_prob, threshold=0.5):
    mask_binary = (mask_prob > threshold).astype(np.uint8)
    kernel = np.ones((5,5), np.uint8)
    mask_binary = cv2.morphologyEx(mask_binary, cv2.MORPH_OPEN, kernel)
    mask_binary = cv2.morphologyEx(mask_binary, cv2.MORPH_CLOSE, kernel)
    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(mask_binary, connectivity=8)
    if num_labels > 1:
        max_label = 1 + np.argmax(stats[1:, cv2.CC_STAT_AREA]) 
        mask_clean = np.zeros_like(mask_binary)
        mask_clean[labels == max_label] = 1
        return mask_clean
    else:
        return mask_binary

def get_bounding_box(mask_pred, padding=0.2):
    contours, _ = cv2.findContours(mask_pred, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    if contours:
        c = max(contours, key=cv2.contourArea)
        x, y, rw, rh = cv2.boundingRect(c)
        pad_w = int(rw * padding); pad_h = int(rh * padding)
        x1 = max(0, x - pad_w); y1 = max(0, y - pad_h)
        x2 = min(mask_pred.shape[1], x + rw + pad_w)
        y2 = min(mask_pred.shape[0], y + rh + pad_h)
        return (x1, y1, x2, y2), "Soft-ROI"
    else:
        h, w = mask_pred.shape
        cy, cx = h//2, w//2; sz = min(h, w)//2
        return (cx-sz, cy-sz, cx+sz, cy+sz), "Fallback"

class GradCAM:
    def __init__(self, model, target_layer):
        self.model = model; self.target_layer = target_layer
        self.gradients = None; self.activations = None
        target_layer.register_forward_hook(self.save_activation)
        target_layer.register_full_backward_hook(self.save_gradient)
    def save_activation(self, module, input, output): self.activations = output
    def save_gradient(self, module, grad_input, grad_output): self.gradients = grad_output[0]
    def __call__(self, x):
        output = self.model(x); idx = torch.argmax(output)
        self.model.zero_grad(); output[0, idx].backward()
        grads = self.gradients[0]; acts = self.activations[0]
        weights = torch.mean(grads, dim=(1, 2), keepdim=True)
        cam = torch.sum(weights * acts, dim=0).cpu().detach().numpy()
        cam = np.maximum(cam, 0)
        cam = cv2.resize(cam, (224, 224))
        cam = (cam - np.min(cam)) / (np.max(cam) + 1e-8)
        return cam, int(idx), torch.nn.functional.softmax(output, dim=1)

def calc_trust_score(probs, mask_area_ratio):
    probs_np = probs.detach().numpy()[0]
    entropy = -np.sum(probs_np * np.log(probs_np + 1e-9))
    max_ent = np.log(4)
    score_cls = 1.0 - (entropy / max_ent)
    score_seg = 0.3 if mask_area_ratio < 0.01 else 0.95
    return 0.7 * score_cls + 0.3 * score_seg

# --- KH·ªûI T·∫†O MODEL ---
try:
    # ·∫®n spinner khi load xong
    with st.sidebar:
        with st.spinner("‚è≥ ƒêang kh·ªüi t·∫°o h·ªá th·ªëng AI..."):
            seg_model, cls_model = load_models()
            cam_extractor = GradCAM(cls_model, cls_model.features[-1])
    # st.sidebar.success("H·ªá th·ªëng s·∫µn s√†ng!")
except Exception as e:
    st.error(f"L·ªói h·ªá th·ªëng: {e}")
    st.stop()


# --- GIAO DI·ªÜN CH√çNH (TABS) ---
st.title("ü©∫ TRUST-MED AI: H·ªó tr·ª£ Ch·∫©n ƒëo√°n H√¨nh ·∫£nh")
st.markdown("### H·ªá th·ªëng ph√¢n t√≠ch Si√™u √¢m v√∫ T·ª± ƒë·ªông h√≥a")

tab1, tab2, tab3 = st.tabs(["üñ•Ô∏è B√†n l√†m vi·ªác (Ch·∫©n ƒëo√°n)", "üìñ H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng", "üìö Ngu·ªìn d·ªØ li·ªáu"])

# ==========================================
# TAB 1: B√ÄN L√ÄM VI·ªÜC (MAIN APP)
# ==========================================
with tab1:
    col_input, col_result = st.columns([1, 2.5])

    with col_input:
        st.info("üì• **Nh·∫≠p li·ªáu**")
        uploaded_file = st.file_uploader("T·∫£i l√™n ·∫£nh si√™u √¢m (DICOM/JPG/PNG):", type=["jpg", "png", "jpeg"])
        
        # C·∫•u h√¨nh nhanh
        with st.expander("‚öôÔ∏è C·∫•u h√¨nh n√¢ng cao"):
            seg_threshold = st.slider("ƒê·ªô nh·∫°y (Sensitivity)", 0.1, 0.9, 0.5, 0.05)
            use_post_process = st.toggle("Kh·ª≠ nhi·ªÖu t·ª± ƒë·ªông", value=True)

    with col_result:
        if uploaded_file is None:
            st.warning("üëà Vui l√≤ng t·∫£i l√™n ·∫£nh si√™u √¢m ƒë·ªÉ b·∫Øt ƒë·∫ßu ph√¢n t√≠ch.")
            st.image("https://img.freepik.com/free-vector/medical-technology-science-background_53876-119566.jpg", use_column_width=True, caption="H·ªá th·ªëng s·∫µn s√†ng ph√¢n t√≠ch")
        else:
            # X·ª¨ L√ù ·∫¢NH
            original_pil = Image.open(uploaded_file).convert("RGB")
            original_np = np.array(original_pil)
            
            # Guardrail Check
            is_valid, msg = validate_image(original_pil)
            
            if not is_valid:
                st.error(f"‚õîÔ∏è ·∫¢NH KH√îNG H·ª¢P L·ªÜ: {msg}")
            else:
                # Progress Bar gi·∫£ l·∫≠p tr·∫£i nghi·ªám ng∆∞·ªùi d√πng
                progress_text = "ƒêang ph√¢n t√≠ch..."
                my_bar = st.progress(0, text=progress_text)
                
                # --- PROCESSING PIPELINE ---
                # 1. Preprocessing
                my_bar.progress(20, text="ƒêang ti·ªÅn x·ª≠ l√Ω ·∫£nh...")
                input_pil, nw, nh, dx, dy = letterbox_image(original_pil, (256, 256))
                to_tensor = transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])
                input_tensor = to_tensor(input_pil).unsqueeze(0).to(DEVICE)

                # 2. Segmentation
                my_bar.progress(50, text="ƒêang ph√¢n ƒëo·∫°n t·ªïn th∆∞∆°ng (U-Net)...")
                with torch.no_grad():
                    mask_logits = seg_model(input_tensor)
                    mask_prob = torch.sigmoid(mask_logits).numpy()[0,0]
                
                mask_valid = mask_prob[dy:dy+nh, dx:dx+nw]
                mask_resized = cv2.resize(mask_valid, (original_np.shape[1], original_np.shape[0]))
                
                if use_post_process:
                    mask_binary = post_process_mask(mask_resized, threshold=seg_threshold)
                else:
                    mask_binary = (mask_resized > seg_threshold).astype(np.uint8)

                # 3. ROI & Classification
                my_bar.progress(80, text="ƒêang ph√¢n lo·∫°i b·ªánh h·ªçc (EfficientNet)...")
                mask_ratio = np.sum(mask_binary) / (original_np.shape[0]*original_np.shape[1])
                
                # Visuals
                mask_display = original_np.copy()
                mask_display[mask_binary == 1] = [0, 255, 0]
                overlay = cv2.addWeighted(original_np, 0.7, mask_display, 0.3, 0)
                
                (x1, y1, x2, y2), roi_type = get_bounding_box(mask_binary)
                roi_img = original_np[y1:y2, x1:x2]
                cv2.rectangle(overlay, (x1, y1), (x2, y2), (255, 0, 0), 4)

                roi_pil = Image.fromarray(roi_img)
                trans_cls = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])
                input_cls = trans_cls(roi_pil).unsqueeze(0).to(DEVICE)

                heatmap, pred_idx, probs = cam_extractor(input_cls)
                trust_score = calc_trust_score(probs, mask_ratio)
                
                probs_np = probs.detach().numpy()[0]
                prob_benign = probs_np[0] + probs_np[1]
                prob_malignant = probs_np[2] + probs_np[3]
                
                my_bar.progress(100, text="Ho√†n t·∫•t!")
                time.sleep(0.5)
                my_bar.empty()

                # --- HI·ªÇN TH·ªä K·∫æT QU·∫¢ (REPORT CARD STYLE) ---
                st.markdown('<div class="report-card">', unsafe_allow_html=True)
                st.subheader("üìã Phi·∫øu K·∫øt Qu·∫£ Ph√¢n T√≠ch")
                
                # Logic k·∫øt lu·∫≠n
                prob_normal = 0.0
                if mask_ratio < 0.005: 
                    prob_normal = 0.95; prob_benign = 0.05; prob_malignant = 0.0
                    status_text = "KH√îNG PH√ÅT HI·ªÜN B·∫§T TH∆Ø·ªúNG (BI-RADS 1)"; status_color = "green"
                    final_conf = prob_normal
                else:
                    if prob_malignant > prob_benign:
                        status_text = "NGHI NG·ªú √ÅC T√çNH (BI-RADS 4/5)"; status_color = "red"
                        final_conf = prob_malignant
                    else:
                        status_text = "KH·∫¢ NƒÇNG CAO L√ÄNH T√çNH (BI-RADS 2/3)"; status_color = "blue"
                        final_conf = prob_benign

                # 1. K·∫øt lu·∫≠n ch√≠nh
                c_res1, c_res2 = st.columns([2, 1])
                with c_res1:
                    st.markdown(f"### K·∫øt lu·∫≠n: :{status_color}[{status_text}]")
                    st.markdown(f"**ƒê·ªô tin c·∫≠y c·ªßa AI:** {trust_score:.1%}")
                with c_res2:
                    if prob_normal > 0.5:
                        st.metric("X√°c su·∫•t B√¨nh th∆∞·ªùng", f"{prob_normal:.1%}")
                    else:
                        st.metric("T·ªâ l·ªá √Åc t√≠nh", f"{prob_malignant:.1%}", delta_color="inverse")
                        st.caption(f"L√†nh t√≠nh: {prob_benign:.1%}")

                st.divider()

                # 2. H√¨nh ·∫£nh tr·ª±c quan
                st.markdown("**üî¨ H√¨nh ·∫£nh ph√¢n t√≠ch chi ti·∫øt:**")
                img_col1, img_col2, img_col3 = st.columns(3)
                
                with img_col1:
                    st.image(original_pil, caption="·∫¢nh g·ªëc (Original)", use_column_width=True)
                with img_col2:
                    st.image(overlay, caption="ƒê·ªãnh v·ªã Kh·ªëi u (Segmentation)", use_column_width=True)
                with img_col3:
                    heatmap_colored = cv2.applyColorMap(np.uint8(255*heatmap), cv2.COLORMAP_JET)
                    heatmap_colored = cv2.cvtColor(heatmap_colored, cv2.COLOR_BGR2RGB)
                    superimposed = cv2.addWeighted(cv2.resize(roi_img, (224,224)), 0.6, heatmap_colored, 0.4, 0)
                    st.image(superimposed, caption="B·∫£n ƒë·ªì nhi·ªát (AI Attention)", use_column_width=True)

                st.markdown("</div>", unsafe_allow_html=True)

# ==========================================
# TAB 2: H∆Ø·ªöNG D·∫™N S·ª¨ D·ª§NG
# ==========================================
with tab2:
    st.header("üìñ H∆∞·ªõng d·∫´n cho ng∆∞·ªùi d√πng m·ªõi")
    
    st.markdown("""
    Ch√†o m·ª´ng b√°c sƒ© ƒë·∫øn v·ªõi h·ªá th·ªëng **TRUST-MED AI**. D∆∞·ªõi ƒë√¢y l√† quy tr√¨nh 3 b∆∞·ªõc ƒë∆°n gi·∫£n:

    ### B∆∞·ªõc 1: Chu·∫©n b·ªã ·∫£nh
    * H·ªá th·ªëng ch·∫•p nh·∫≠n c√°c file ·∫£nh ƒë·ªãnh d·∫°ng **.JPG, .PNG**.
    * ƒê·∫£m b·∫£o ·∫£nh l√† **·∫£nh si√™u √¢m (Grayscale)**, kh√¥ng ch·ª©a c√°c ghi ch√∫ m√†u qu√° l·ªõn.
    * C·∫Øt b·ªè c√°c th√¥ng tin nh·∫°y c·∫£m c·ªßa b·ªánh nh√¢n (t√™n, tu·ªïi) tr∆∞·ªõc khi t·∫£i l√™n n·∫øu c·∫ßn.

    ### B∆∞·ªõc 2: T·∫£i ·∫£nh v√† Ph√¢n t√≠ch
    1.  Chuy·ªÉn sang Tab **"üñ•Ô∏è B√†n l√†m vi·ªác"**.
    2.  Nh·∫•n n√∫t **"Browse files"** ·ªü c·ªôt b√™n tr√°i ƒë·ªÉ ch·ªçn ·∫£nh t·ª´ m√°y t√≠nh.
    3.  H·ªá th·ªëng s·∫Ω t·ª± ƒë·ªông ki·ªÉm tra ch·∫•t l∆∞·ª£ng ·∫£nh v√† ch·∫°y ph√¢n t√≠ch (m·∫•t kho·∫£ng 1-3 gi√¢y).

    ### B∆∞·ªõc 3: ƒê·ªçc k·∫øt qu·∫£
    * **K·∫øt lu·∫≠n:** AI s·∫Ω ƒë∆∞a ra g·ª£i √Ω ph√¢n lo·∫°i (L√†nh t√≠nh/√Åc t√≠nh/B√¨nh th∆∞·ªùng).
    * **ƒê·ªãnh v·ªã:** Quan s√°t v√πng m√†u xanh l√° c√¢y tr√™n ·∫£nh ƒë·ªÉ xem v·ªã tr√≠ kh·ªëi u AI ph√°t hi·ªán.
    * **B·∫£n ƒë·ªì nhi·ªát:** V√πng m√†u ƒë·ªè tr√™n ·∫£nh th·ª© 3 cho bi·∫øt n∆°i AI "t·∫≠p trung nh√¨n v√†o" ƒë·ªÉ ƒë∆∞a ra quy·∫øt ƒë·ªãnh.
    
    ---
    **‚ö†Ô∏è L∆∞u √Ω quan tr·ªçng:** *K·∫øt qu·∫£ c·ªßa AI ch·ªâ mang t√≠nh ch·∫•t tham kh·∫£o h·ªó tr·ª£ (Second Opinion). Quy·∫øt ƒë·ªãnh l√¢m s√†ng cu·ªëi c√πng lu√¥n thu·ªôc v·ªÅ b√°c sƒ© chuy√™n khoa.*
    """)

# ==========================================
# TAB 3: D·ªÆ LI·ªÜU & TR√çCH D·∫™N
# ==========================================
with tab3:
    st.header("üìö C∆° s·ªü d·ªØ li·ªáu hu·∫•n luy·ªán")
    st.markdown("H·ªá th·ªëng TRUST-MED ƒë∆∞·ª£c hu·∫•n luy·ªán d·ª±a tr√™n s·ª± t·ªïng h·ª£p c·ªßa **12 b·ªô d·ªØ li·ªáu si√™u √¢m v√∫** uy t√≠n tr√™n th·∫ø gi·ªõi v√† t·∫°i Vi·ªát Nam, bao g·ªìm:")
    
    # Danh s√°ch 12 dataset (Gi·∫£ l·∫≠p d·ª±a tr√™n c√°c dataset ph·ªï bi·∫øn nh·∫•t trong nghi√™n c·ª©u Breast US)
    datasets = [
        {"name": "BUSI (Breast Ultrasound Images)", "source": "Cairo University, Egypt", "desc": "B·ªô d·ªØ li·ªáu ti√™u chu·∫©n v√†ng v·ªõi m·∫∑t n·∫° ph√¢n ƒëo·∫°n chi ti·∫øt."},
        {"name": "BUSBRA (Breast Ultrasound Brazil)", "source": "Brazil", "desc": "D·ªØ li·ªáu ƒëa trung t√¢m v·ªõi ƒë·ªô ƒëa d·∫°ng cao v·ªÅ thi·∫øt b·ªã."},
        {"name": "UDIAT (Dataset B)", "source": "Parc Taul√≠ Hospital, Spain", "desc": "Chuy√™n v·ªÅ c√°c t·ªïn th∆∞∆°ng nh·ªè v√† kh√≥ ph√°t hi·ªán."},
        {"name": "OASBUD", "source": "Ba Lan", "desc": "D·ªØ li·ªáu m·ªü v·ªÅ si√™u √¢m v√∫ v·ªõi nh√£n BI-RADS chi ti·∫øt."},
        {"name": "STU (Shantou University)", "source": "China", "desc": "T·∫≠p d·ªØ li·ªáu l·ªõn t·ª´ b·ªánh vi·ªán Shantou."},
        {"name": "Thamburaj Dataset", "source": "Private Collection", "desc": "T·∫≠p trung v√†o ƒë·∫∑c tr∆∞ng h√¨nh th√°i kh·ªëi u."},
        {"name": "HMSS (Hospital Move S.S.)", "source": "Mexico", "desc": "D·ªØ li·ªáu th·ª±c t·∫ø l√¢m s√†ng t·∫°i Mexico."},
        {"name": "Mendeley Data V2", "source": "Rodrigues et al.", "desc": "T·ªïng h·ª£p c√°c ca si√™u √¢m v√∫ l√†nh t√≠nh v√† √°c t√≠nh."},
        {"name": "BrEaST-Lesions", "source": "Kaggle/Open Source", "desc": "T·∫≠p h·ª£p ƒëa d·∫°ng c√°c lo·∫°i t·ªïn th∆∞∆°ng v√∫."},
        {"name": "Dataset A (Private)", "source": "Nghi√™n c·ª©u n·ªôi b·ªô", "desc": "D·ªØ li·ªáu thu th·∫≠p b·ªï sung ƒë·ªÉ c√¢n b·∫±ng nh√£n."},
        {"name": "VinDr-Mammo (Tham chi·∫øu)", "source": "VinBigData", "desc": "D·ªØ li·ªáu tham chi·∫øu ƒë·∫∑c ƒëi·ªÉm t·ªïn th∆∞∆°ng tr√™n ng∆∞·ªùi Vi·ªát."},
        {"name": "HisBreast (Vietnamese Clinical Data)", "source": "B·ªánh vi·ªán t·∫°i Vi·ªát Nam", "desc": "D·ªØ li·ªáu l√¢m s√†ng th·ª±c t·∫ø thu th·∫≠p t·∫°i Vi·ªát Nam (Key Dataset)."}
    ]

    for i, ds in enumerate(datasets):
        with st.expander(f"{i+1}. {ds['name']}"):
            st.write(f"**Ngu·ªìn:** {ds['source']}")
            st.write(f"**M√¥ t·∫£:** {ds['desc']}")
            
    st.info("üí° Vi·ªác k·∫øt h·ª£p ƒëa ngu·ªìn d·ªØ li·ªáu gi√∫p TRUST-MED c√≥ kh·∫£ nƒÉng kh√°ng nhi·ªÖu t·ªët (Robustness) v√† gi·∫£m thi·ªÉu hi·ªán t∆∞·ª£ng Overfitting.")
